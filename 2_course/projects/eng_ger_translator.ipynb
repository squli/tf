{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaI15qB0rXdG"
      },
      "source": [
        "# Capstone Project\n",
        "## Neural translation model\n",
        "### Instructions\n",
        "\n",
        "In this notebook, you will create a neural network that translates from English to German. You will use concepts from throughout this course, including building more flexible model architectures, freezing layers, data processing pipeline and sequence modelling.\n",
        "\n",
        "This project is peer-assessed. Within this notebook you will find instructions in each section for how to complete the project. Pay close attention to the instructions as the peer review will be carried out according to a grading rubric that checks key parts of the project instructions. Feel free to add extra cells into the notebook as required.\n",
        "\n",
        "### How to submit\n",
        "\n",
        "When you have completed the Capstone project notebook, you will submit a pdf of the notebook for peer review. First ensure that the notebook has been fully executed from beginning to end, and all of the cell outputs are visible. This is important, as the grading rubric depends on the reviewer being able to view the outputs of your notebook. Save the notebook as a pdf (File -> Download as -> PDF via LaTeX). You should then submit this pdf for review.\n",
        "\n",
        "### Let's get started!\n",
        "\n",
        "We'll start by running some imports, and loading the dataset. For this project you are free to make further imports throughout the notebook as you wish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hOvyfpnjrXdK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e3acfe0-f783-4c86-c269-5248bef82919",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c52e3004-ed90-4377-8a74-305067e98f33\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c52e3004-ed90-4377-8a74-305067e98f33\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving deu.txt to deu.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'deu.txt': b'Hi.\\tHallo!\\tCC}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.layers import Layer, Input, Masking, LSTM, Embedding, Dense, Dropout\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFJpxR-ErXdM"
      },
      "source": [
        "![Flags overview image](data/germany_uk_flags.png)\n",
        "\n",
        "For the capstone project, you will use a language dataset from http://www.manythings.org/anki/ to build a neural translation model. This dataset consists of over 200,000 pairs of sentences in English and German. In order to make the training quicker, we will restrict to our dataset to 20,000 pairs. Feel free to change this if you wish - the size of the dataset used is not part of the grading rubric.\n",
        "\n",
        "Your goal is to develop a neural translation model from English to German, making use of a pre-trained English word embedding module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "neRSHR6OrXdM"
      },
      "outputs": [],
      "source": [
        "# Run this cell to load the dataset\n",
        "\n",
        "NUM_EXAMPLES = 5000\n",
        "data_examples = []\n",
        "with open('deu.txt', 'r', encoding='utf8') as f:\n",
        "    for line in f.readlines():\n",
        "        if len(data_examples) < NUM_EXAMPLES:\n",
        "            data_examples.append(line)\n",
        "        else:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bAveev0zrXdM"
      },
      "outputs": [],
      "source": [
        "# These functions preprocess English and German sentences\n",
        "\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"ü\", 'ue', sentence)\n",
        "    sentence = re.sub(r\"ä\", 'ae', sentence)\n",
        "    sentence = re.sub(r\"ö\", 'oe', sentence)\n",
        "    sentence = re.sub(r'ß', 'ss', sentence)\n",
        "\n",
        "    sentence = unicode_to_ascii(sentence)\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r\"[^a-z?.!,']+\", \" \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "\n",
        "    return sentence.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2fbSKpWrXdM"
      },
      "source": [
        "#### The custom translation model\n",
        "The following is a schematic of the custom translation model architecture you will develop in this project.\n",
        "\n",
        "![Model Schematic](data/neural_translation_model.png)\n",
        "\n",
        "Key:\n",
        "![Model key](data/neural_translation_model_key.png)\n",
        "\n",
        "The custom model consists of an encoder RNN and a decoder RNN. The encoder takes words of an English sentence as input, and uses a pre-trained word embedding to embed the words into a 128-dimensional space. To indicate the end of the input sentence, a special end token (in the same 128-dimensional space) is passed in as an input. This token is a TensorFlow Variable that is learned in the training phase (unlike the pre-trained word embedding, which is frozen).\n",
        "\n",
        "The decoder RNN takes the internal state of the encoder network as its initial state. A start token is passed in as the first input, which is embedded using a learned German word embedding. The decoder RNN then makes a prediction for the next German word, which during inference is then passed in as the following input, and this process is repeated until the special `<end>` token is emitted from the decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtduLAX7rXdN"
      },
      "source": [
        "## 1. Text preprocessing\n",
        "* Create separate lists of English and German sentences, and preprocess them using the `preprocess_sentence` function provided for you above.\n",
        "* Add a special `\"<start>\"` and `\"<end>\"` token to the beginning and end of every German sentence.\n",
        "* Use the Tokenizer class from the `tf.keras.preprocessing.text` module to tokenize the German sentences, ensuring that no character filters are applied. _Hint: use the Tokenizer's \"filter\" keyword argument._\n",
        "* Print out at least 5 randomly chosen examples of (preprocessed) English and German sentence pairs. For the German sentence, print out the text (with start and end tokens) as well as the tokenized sequence.\n",
        "* Pad the end of the tokenized German sequences with zeros, and batch the complete set of sequences into one numpy array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "scrolled": true,
        "id": "19XYiMTbrXdN",
        "outputId": "b990dfde-7fe3-42f9-8cf8-6f97222a48fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He's good.\tEr ist gut.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1855193 (Spamster) & #1857848 (Pfirsichbaeumchen)\n",
            "\n",
            "he's good .\n",
            "er ist gut .\n"
          ]
        }
      ],
      "source": [
        "# Create separate lists of English and German sentences, and preprocess them using the preprocess_sentence function provided\n",
        "# for you above.\n",
        "\n",
        "def parse_input_data(input_data:list):\n",
        "    english_sentences = []\n",
        "    german_sentences = []\n",
        "    for string in input_data:\n",
        "        splitted = string.split(\"\\t\")\n",
        "        english_sentences.append(preprocess_sentence(splitted[0]))\n",
        "        german_sentences.append(preprocess_sentence(splitted[1]))\n",
        "    return english_sentences, german_sentences\n",
        "\n",
        "english_sentences, german_sentences = parse_input_data(data_examples)\n",
        "\n",
        "print(data_examples[563])\n",
        "print(english_sentences[563])\n",
        "print(german_sentences[563])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OdruvcyrrXdO",
        "outputId": "17ab4979-3f63-480d-c7e7-2783fe7f0b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He's good.\tEr ist gut.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1855193 (Spamster) & #1857848 (Pfirsichbaeumchen)\n",
            "\n",
            "he's good .\n",
            "er ist gut .\n",
            "<start> he's good . <end>\n",
            "<start> er ist gut . <end>\n"
          ]
        }
      ],
      "source": [
        "# Add a special \"<start>\" and \"<end>\" token to the beginning and end of every German sentence.\n",
        "\n",
        "def add_tokens(line):\n",
        "    line_with_tokens = \"<start> \"\n",
        "    line_with_tokens += line\n",
        "    line_with_tokens += \" <end>\"\n",
        "    return line_with_tokens\n",
        "\n",
        "english_sentences_tokens = []\n",
        "for s in english_sentences:\n",
        "    english_sentences_tokens.append(add_tokens(s))\n",
        "\n",
        "german_sentences_tokens = []\n",
        "for s in german_sentences:\n",
        "    german_sentences_tokens.append(add_tokens(s))\n",
        "\n",
        "print(data_examples[563])\n",
        "print(english_sentences[563])\n",
        "print(german_sentences[563])\n",
        "print(english_sentences_tokens[563])\n",
        "print(german_sentences_tokens[563])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-LtsypqnrXdO"
      },
      "outputs": [],
      "source": [
        "# Use the Tokenizer class from the tf.keras.preprocessing.text module to tokenize the German sentences,\n",
        "# ensuring that no character filters are applied. Hint: use the Tokenizer's \"filter\" keyword argument.\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(filters='')\n",
        "tokenizer.fit_on_texts(german_sentences_tokens)\n",
        "sequences = tokenizer.texts_to_sequences(german_sentences_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JWu7FNvBrXdP"
      },
      "outputs": [],
      "source": [
        "# Print out at least 5 randomly chosen examples of (preprocessed) English and German sentence pairs.\n",
        "# For the German sentence, print out the text (with start and end tokens) as well as the tokenized sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "d56RT53qrXdP",
        "outputId": "12fd1a92-ffea-4f19-e08f-4c8e91c8b882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------\n",
            "<start> have another . <end> -> <start> nehmen sie noch eins . <end> / [1, 142, 8, 72, 202, 3, 2]\n",
            "--------\n",
            "<start> beat it . <end> -> <start> scher dich weg ! <end> / [1, 192, 21, 65, 5, 2]\n",
            "--------\n",
            "<start> they love it . <end> -> <start> sie lieben es . <end> / [1, 8, 295, 10, 3, 2]\n",
            "--------\n",
            "<start> do i look ok ? <end> -> <start> seh ich ok aus ? <end> / [1, 1026, 4, 1697, 61, 9, 2]\n",
            "--------\n",
            "<start> tom may win . <end> -> <start> tom kann gewinnen . <end> / [1, 6, 29, 222, 3, 2]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "random_integers = [random.randint(0, 5000) for _ in range(5)]\n",
        "\n",
        "for r in random_integers:\n",
        "    print(\"--------\")\n",
        "    print(f\"{english_sentences_tokens[r]} -> {german_sentences_tokens[r]} / {sequences[r]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "H726uC-urXdP"
      },
      "outputs": [],
      "source": [
        "# Pad the end of the tokenized German sequences with zeros, and batch the complete set of sequences into one numpy array.\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Pad the sequences\n",
        "padded_german_sequences = pad_sequences(sequences, padding='post')\n",
        "\n",
        "# Convert to numpy array\n",
        "padded_german_sequences_array = np.array(padded_german_sequences)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ-g1MrvrXdP"
      },
      "source": [
        "## 2. Prepare the data with tf.data.Dataset objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnmfJWNJrXdP"
      },
      "source": [
        "#### Load the embedding layer\n",
        "As part of the dataset preproceessing for this project, you will use a pre-trained English word embedding module from TensorFlow Hub. The URL for the module is https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1. This module has also been made available as a complete saved model in the folder `'./models/tf2-preview_nnlm-en-dim128_1'`.\n",
        "\n",
        "This embedding takes a batch of text tokens in a 1-D tensor of strings as input. It then embeds the separate tokens into a 128-dimensional space.\n",
        "\n",
        "The code to load and test the embedding layer is provided for you below.\n",
        "\n",
        "**NB:** this model can also be used as a sentence embedding module. The module will process each token by removing punctuation and splitting on spaces. It then averages the word embeddings over a sentence to give a single embedding vector. However, we will use it only as a word embedding module, and will pass each word in the input sentence as a separate token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B2s4gfnurXdP",
        "outputId": "25e0cf8d-a56f-4305-8b79-48782ffb6a22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'models': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yZuI2VYyrXdQ",
        "outputId": "4a923961-8374-4251-b336-aa91683ab02c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow_hub.keras_layer.KerasLayer object at 0x7bf6e61db5b0>\n"
          ]
        }
      ],
      "source": [
        "# Load embedding module from Tensorflow Hub\n",
        "#embedding_layer = hub.KerasLayer(\"tf2-preview_nnlm-en-dim128_1\",\n",
        "#                                 output_shape=[128], input_shape=[], dtype=tf.string)\n",
        "embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\",\n",
        "                                 output_shape=[128], input_shape=[], dtype=tf.string)\n",
        "print(embedding_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SCthjs5_rXdQ",
        "outputId": "5077e3d9-6e58-4cc3-a426-20fda840870a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([7, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Test the layer\n",
        "\n",
        "embedding_layer(tf.constant([\"these\", \"aren't\", \"the\", \"droids\", \"you're\", \"looking\", \"for\"])).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8VsCpPVrXdQ"
      },
      "source": [
        "You should now prepare the training and validation Datasets.\n",
        "\n",
        "* Create a random training and validation set split of the data, reserving e.g. 20% of the data for validation (NB: each English dataset example is a single sentence string, and each German dataset example is a sequence of padded integer tokens).\n",
        "* Load the training and validation sets into a tf.data.Dataset object, passing in a tuple of English and German data for both training and validation sets.\n",
        "* Create a function to map over the datasets that splits each English sentence at spaces. Apply this function to both Dataset objects using the map method. _Hint: look at the tf.strings.split function._\n",
        "* Create a function to map over the datasets that embeds each sequence of English words using the loaded embedding layer/model. Apply this function to both Dataset objects using the map method.\n",
        "* Create a function to filter out dataset examples where the English sentence is more than 13 (embedded) tokens in length. Apply this function to both Dataset objects using the filter method.\n",
        "* Create a function to map over the datasets that pads each English sequence of embeddings with some distinct padding value before the sequence, so that each sequence is length 13. Apply this function to both Dataset objects using the map method. _Hint: look at the tf.pad function. You can extract a Tensor shape using tf.shape; you might also find the tf.math.maximum function useful._\n",
        "* Batch both training and validation Datasets with a batch size of 16.\n",
        "* Print the `element_spec` property for the training and validation Datasets.\n",
        "* Using the Dataset `.take(1)` method, print the shape of the English data example from the training Dataset.\n",
        "* Using the Dataset `.take(1)` method, print the German data example Tensor from the validation Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "92oeYqOorXdQ",
        "outputId": "1d5be741-3bbb-4056-d38d-108990ee3709",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> i'm chubby . <end> - [  1   4  11 864   3   2   0   0   0   0   0]\n",
            "<start> i'm stunned . <end> - [   1    4   11 1523    3    2    0    0    0    0    0]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# Create a random training and validation set split of the data, reserving e.g. 20% of the data for validation\n",
        "# (NB: each English dataset example is a single sentence string, and each German dataset example is a\n",
        "# sequence of padded integer tokens).\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "english_train, english_val, german_train, german_val = train_test_split(\n",
        "    english_sentences_tokens, padded_german_sequences, test_size=0.1)\n",
        "\n",
        "print(f\"{english_train[5]} - {german_train[5]}\")\n",
        "print(f\"{english_val[5]} - {german_val[5]}\")\n",
        "print(type(german_val[5]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "tFsiYOusrXdR",
        "outputId": "6b3fb596-1f42-4c17-e589-ccec10e2481d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(11,), dtype=tf.int32, name=None))>\n",
            "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(11,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# Load the training and validation sets into a tf.data.Dataset object,\n",
        "# passing in a tuple of English and German data for both training and validation sets.\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((english_train, german_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((english_val, german_val))\n",
        "\n",
        "print(train_dataset)\n",
        "print(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "0lXqjZQ7rXdR",
        "outputId": "d87ffa19-a25f-40af-b92a-a20a58748121",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_MapDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(11,), dtype=tf.int32, name=None))>\n",
            "<_MapDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(11,), dtype=tf.int32, name=None))>\n",
            "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n",
            "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n"
          ]
        }
      ],
      "source": [
        "# Create a function to map over the datasets that splits each English sentence at spaces.\n",
        "# Apply this function to both Dataset objects using the map method. Hint: look at the tf.strings.split function.\n",
        "\n",
        "def split_english(sentence, target):\n",
        "    sentence = tf.strings.split(sentence)\n",
        "    if isinstance(sentence, tf.RaggedTensor):\n",
        "        sentence = sentence.to_tensor()\n",
        "    sentence = tf.reshape(sentence, [-1])\n",
        "    return sentence, target\n",
        "\n",
        "# Apply the function to both datasets\n",
        "train_dataset = train_dataset.map(split_english)\n",
        "val_dataset = val_dataset.map(split_english)\n",
        "\n",
        "print(train_dataset)\n",
        "print(val_dataset)\n",
        "\n",
        "print(type(train_dataset))\n",
        "print(type(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "Hps4B7JIrXdR",
        "outputId": "735558c1-8f5e-442f-bada-b63c9375c947",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_MapDataset element_spec=(TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), TensorSpec(shape=(11,), dtype=tf.int32, name=None))>\n",
            "<_MapDataset element_spec=(TensorSpec(shape=(None, 128), dtype=tf.float32, name=None), TensorSpec(shape=(11,), dtype=tf.int32, name=None))>\n",
            "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n",
            "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n"
          ]
        }
      ],
      "source": [
        "# Create a function to map over the datasets that embeds each sequence of English words using the loaded embedding layer/model.\n",
        "# Apply this function to both Dataset objects using the map method.\n",
        "\n",
        "def embed_english(sentence, target):\n",
        "    sentence = embedding_layer(sentence)\n",
        "    return sentence, target\n",
        "\n",
        "train_dataset = train_dataset.map(embed_english)\n",
        "val_dataset = val_dataset.map(embed_english)\n",
        "\n",
        "print(train_dataset)\n",
        "print(val_dataset)\n",
        "\n",
        "print(type(train_dataset))\n",
        "print(type(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "9JIZywLJrXdS"
      },
      "outputs": [],
      "source": [
        "# Create a function to filter out dataset examples where the English sentence is more than 13 (embedded) tokens in length.\n",
        "# Apply this function to both Dataset objects using the filter method.\n",
        "\n",
        "# Function to filter out long English sentences\n",
        "def filter_long_sentences(sentence, target):\n",
        "    return tf.shape(sentence)[0] <= 13\n",
        "\n",
        "# Apply the function to both datasets\n",
        "train_dataset = train_dataset.filter(filter_long_sentences)\n",
        "val_dataset = val_dataset.filter(filter_long_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "IbeVTzRRrXdS"
      },
      "outputs": [],
      "source": [
        "# Create a function to map over the datasets that pads each English sequence of embeddings with some distinct padding\n",
        "# value before the sequence, so that each sequence is length 13. Apply this function to both Dataset objects using\n",
        "# the map method. Hint: look at the tf.pad function. You can extract a Tensor shape using tf.shape; you might also\n",
        "# find the tf.math.maximum function useful.\n",
        "\n",
        "# Function to pad each English sequence to length 13\n",
        "def pad_english(sentence, target):\n",
        "    max_length = 13\n",
        "    padding_value = -1.0  # Distinct padding value\n",
        "    sentence = tf.pad(sentence, [[max_length - tf.shape(sentence)[0], 0], [0, 0]], constant_values=padding_value)\n",
        "    return sentence, target\n",
        "\n",
        "# Apply the function to both datasets\n",
        "train_dataset = train_dataset.map(pad_english)\n",
        "val_dataset = val_dataset.map(pad_english)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "DsTYEckerXdS"
      },
      "outputs": [],
      "source": [
        "# Batch both training and validation Datasets with a batch size of 16.\n",
        "batch_size = 16\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Sw0UTehprXdT",
        "outputId": "665bde9a-69a2-4940-a2ae-1ccb37dc8a2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(TensorSpec(shape=(None, None, 128), dtype=tf.float32, name=None), TensorSpec(shape=(None, 11), dtype=tf.int32, name=None))\n",
            "(TensorSpec(shape=(None, None, 128), dtype=tf.float32, name=None), TensorSpec(shape=(None, 11), dtype=tf.int32, name=None))\n"
          ]
        }
      ],
      "source": [
        "# Print the element_spec property for the training and validation Datasets.\n",
        "print(train_dataset.element_spec)\n",
        "print(val_dataset.element_spec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "JYhGa4GNrXdT",
        "outputId": "ed78cf2a-bf89-4324-ef78-62f3de58dcd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 13, 128)\n"
          ]
        }
      ],
      "source": [
        "# Using the Dataset .take(1) method, print the shape of the English data example from the training Dataset.\n",
        "for english_data, _ in train_dataset.take(1):\n",
        "    print(english_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "9ySnPAO-rXdT",
        "outputId": "5901aec3-684a-46a4-c89e-2190a69c8911",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 11)\n"
          ]
        }
      ],
      "source": [
        "# Using the Dataset .take(1) method, print the German data example Tensor from the validation Dataset.\n",
        "for _, g_data in val_dataset.take(1):\n",
        "    print(g_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOeKhuL-rXdU"
      },
      "source": [
        "## 3. Create the custom layer\n",
        "You will now create a custom layer to add the learned end token embedding to the encoder model:\n",
        "\n",
        "![Encoder schematic](data/neural_translation_model_encoder.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7F6B9q4rXdU"
      },
      "source": [
        "You should now build the custom layer.\n",
        "* Using layer subclassing, create a custom layer that takes a batch of English data examples from one of the Datasets, and adds a learned embedded ‘end’ token to the end of each sequence.\n",
        "* This layer should create a TensorFlow Variable (that will be learned during training) that is 128-dimensional (the size of the embedding space). _Hint: you may find it helpful in the call method to use the tf.tile function to replicate the end token embedding across every element in the batch._\n",
        "* Using the Dataset `.take(1)` method, extract a batch of English data examples from the training Dataset and print the shape. Test the custom layer by calling the layer on the English data batch Tensor and print the resulting Tensor shape (the layer should increase the sequence length by one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "8O9qcd1KrXdU"
      },
      "outputs": [],
      "source": [
        "# Using layer subclassing, create a custom layer that takes a batch of English data examples from one of the Datasets,\n",
        "# and adds a learned embedded ‘end’ token to the end of each sequence.\n",
        "# This layer should create a TensorFlow Variable (that will be learned during training)\n",
        "# that is 128-dimensional (the size of the embedding space).\n",
        "# Hint: you may find it helpful in the call method to use the tf.tile function to replicate the end token embedding\n",
        "# across every element in the batch.\n",
        "\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# Define the custom layer\n",
        "class AddEndTokenLayer(Layer):\n",
        "    def __init__(self, embedding_dim=128, **kwargs):\n",
        "        super(AddEndTokenLayer, self).__init__(**kwargs)\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Initialize the learned end token embedding\n",
        "        self.end_token_embedding = self.add_weight(\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='random_normal',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        end_token = tf.tile(tf.reshape(self.end_token_embedding,\n",
        "                                       shape=(1, 1, self.end_token_embedding.shape[0])),\n",
        "                            [tf.shape(inputs)[0],1,1])\n",
        "        return tf.keras.layers.concatenate([inputs, end_token], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "yoi6WVMNrXdU",
        "outputId": "52de8ebf-27ed-4d20-e0ed-b5e968693bfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 13, 128)\n",
            "(16, 14, 128)\n"
          ]
        }
      ],
      "source": [
        "# Using the Dataset .take(1) method, extract a batch of English data examples from the training Dataset and print the shape.\n",
        "# Test the custom layer by calling the layer on the English data batch Tensor and\n",
        "# print the resulting Tensor shape (the layer should increase the sequence length by one).\n",
        "\n",
        "for english_data, _ in train_dataset.take(1):\n",
        "    print(english_data.shape)\n",
        "    break\n",
        "\n",
        "addEndTokenLayer = AddEndTokenLayer(embedding_dim=128)\n",
        "output_data = addEndTokenLayer(english_data)\n",
        "print(output_data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ueTBZn3rXdV"
      },
      "source": [
        "## 4. Build the encoder network\n",
        "The encoder network follows the schematic diagram above. You should now build the RNN encoder model.\n",
        "* Using the functional API, build the encoder network according to the following spec:\n",
        "    * The model will take a batch of sequences of embedded English words as input, as given by the Dataset objects.\n",
        "    * The next layer in the encoder will be the custom layer you created previously, to add a learned end token embedding to the end of the English sequence.\n",
        "    * This is followed by a Masking layer, with the `mask_value` set to the distinct padding value you used when you padded the English sequences with the Dataset preprocessing above.\n",
        "    * The final layer is an LSTM layer with 512 units, which also returns the hidden and cell states.\n",
        "    * The encoder is a multi-output model. There should be two output Tensors of this model: the hidden state and cell states of the LSTM layer. The output of the LSTM layer is unused.\n",
        "* Using the Dataset `.take(1)` method, extract a batch of English data examples from the training Dataset and test the encoder model by calling it on the English data Tensor, and print the shape of the resulting Tensor outputs.\n",
        "* Print the model summary for the encoder network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "v-YY1udNrXdV",
        "outputId": "661dc575-c9d7-41b1-eb0e-a2260987a992",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_end_token_layer_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │            \u001b[38;5;34m128\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mAddEndTokenLayer\u001b[0m)        │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_2 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ add_end_token_layer_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ masking_2 (\u001b[38;5;33mMasking\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ add_end_token_layer_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ any_2 (\u001b[38;5;33mAny\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │      \u001b[38;5;34m1,312,768\u001b[0m │ masking_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ any_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│                           │ \u001b[38;5;34m512\u001b[0m)]                  │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_end_token_layer_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AddEndTokenLayer</span>)        │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_end_token_layer_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ masking_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_end_token_layer_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ any_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ masking_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ any_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                  │                │                        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,312,896\u001b[0m (5.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,896</span> (5.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,312,896\u001b[0m (5.01 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,896</span> (5.01 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Masking\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def build_encoder_model(input_shape):\n",
        "    # Input layer\n",
        "    inputs = Input([13, input_shape])\n",
        "\n",
        "    # Add custom layer\n",
        "    v = AddEndTokenLayer(embedding_dim=128)(inputs)\n",
        "\n",
        "    # Add Masking layer\n",
        "    v = Masking([(lambda x: x*0)(x) for x in range(128)])(v)\n",
        "\n",
        "    # Add LSTM layer with return state\n",
        "    lstm_out, hidden_state, cell_state = LSTM(512, return_sequences=True, return_state=True)(v)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=inputs, outputs=[hidden_state, cell_state])\n",
        "\n",
        "    return model\n",
        "\n",
        "encoder_model = build_encoder_model(128)\n",
        "encoder_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "j5vOrA6TrXdV",
        "outputId": "db53ea2e-d1e6-4a68-9d6a-be16705e2993",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English shape after model (16, 512)\n",
            "German shape after model (16, 512)\n"
          ]
        }
      ],
      "source": [
        "# Using the Dataset .take(1) method, extract a batch of English data examples from the training Dataset\n",
        "# and test the encoder model by calling it on the English data Tensor,\n",
        "# and print the shape of the resulting Tensor outputs.\n",
        "\n",
        "for english, german in train_dataset.take(1):\n",
        "    r1, r2 = encoder_model(english)\n",
        "    print(f\"English shape after model {r1.shape}\")\n",
        "    print(f\"German shape after model {r2.shape}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unnkd1jbrXdV"
      },
      "source": [
        "## 5. Build the decoder network\n",
        "The decoder network follows the schematic diagram below.\n",
        "\n",
        "![Decoder schematic](data/neural_translation_model_decoder.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiqAR8x0rXdV"
      },
      "source": [
        "You should now build the RNN decoder model.\n",
        "* Using Model subclassing, build the decoder network according to the following spec:\n",
        "    * The initializer should create the following layers:\n",
        "        * An Embedding layer with vocabulary size set to the number of unique German tokens, embedding dimension 128, and set to mask zero values in the input.\n",
        "        * An LSTM layer with 512 units, that returns its hidden and cell states, and also returns sequences.\n",
        "        * A Dense layer with number of units equal to the number of unique German tokens, and no activation function.\n",
        "    * The call method should include the usual `inputs` argument, as well as the additional keyword arguments `hidden_state` and `cell_state`. The default value for these keyword arguments should be `None`.\n",
        "    * The call method should pass the inputs through the Embedding layer, and then through the LSTM layer. If the `hidden_state` and `cell_state` arguments are provided, these should be used for the initial state of the LSTM layer. _Hint: use the_ `initial_state` _keyword argument when calling the LSTM layer on its input._\n",
        "    * The call method should pass the LSTM output sequence through the Dense layer, and return the resulting Tensor, along with the hidden and cell states of the LSTM layer.\n",
        "* Using the Dataset `.take(1)` method, extract a batch of English and German data examples from the training Dataset. Test the decoder model by first calling the encoder model on the English data Tensor to get the hidden and cell states, and then call the decoder model on the German data Tensor and hidden and cell states, and print the shape of the resulting decoder Tensor outputs.\n",
        "* Print the model summary for the decoder network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "pqBkP-HIrXdW",
        "outputId": "bfcb17bd-eac6-4ea5-f4e2-e10a63d3057b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:372: UserWarning: `build()` was called on layer 'decoder_2', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "unique_tokens = len(tokenizer.word_index) + 1\n",
        "\n",
        "class Decoder(Model):\n",
        "    def __init__(self, unique_tokens, **kwargs):\n",
        "        super(Decoder, self).__init__(**kwargs)\n",
        "        self.embedding = Embedding(input_dim=unique_tokens, output_dim=128, mask_zero=True)\n",
        "        self.lstm = LSTM(512, return_sequences=True, return_state=True)\n",
        "        self.dense = Dense(unique_tokens)\n",
        "\n",
        "    def call(self, inputs, hidden_state=None, cell_state=None):\n",
        "        x = self.embedding(inputs)\n",
        "        if hidden_state is not None and cell_state is not None:\n",
        "            x, hidden, cell = self.lstm(x, initial_state=[hidden_state, cell_state])\n",
        "        else:\n",
        "            x, hidden, cell = self.lstm(x)\n",
        "        x = self.dense(x)\n",
        "        return x, hidden, cell\n",
        "\n",
        "decoder_model = Decoder(unique_tokens)\n",
        "decoder_model.build((16, 12))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "0L0EUSc8rXda",
        "outputId": "62722635-1f84-46c3-82a2-d5b41ebe98cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden shape after encoder_model (16, 512)\n",
            "cell shape after encoder_model (16, 512)\n",
            "Decoder shape after decoder_model (16, 11, 2235)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"decoder_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │         \u001b[38;5;34m286,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ((\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m),  │       \u001b[38;5;34m1,312,768\u001b[0m │\n",
              "│                                      │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m512\u001b[0m))                  │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m2235\u001b[0m)              │       \u001b[38;5;34m1,146,555\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">286,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │\n",
              "│                                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>))                  │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2235</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,146,555</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,745,403\u001b[0m (10.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,745,403</span> (10.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,745,403\u001b[0m (10.47 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,745,403</span> (10.47 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "for english, german in train_dataset.take(1):\n",
        "    r1, r2 = encoder_model(english)\n",
        "    print(f\"hidden shape after encoder_model {r1.shape}\")\n",
        "    print(f\"cell shape after encoder_model {r2.shape}\")\n",
        "\n",
        "    r1, _, _ = decoder_model(german, r1, r2)\n",
        "    print(f\"Decoder shape after decoder_model {r1.shape}\")\n",
        "    break\n",
        "\n",
        "decoder_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqeGDLtZrXda"
      },
      "source": [
        "## 6. Make a custom training loop\n",
        "You should now write a custom training loop to train your custom neural translation model.\n",
        "* Define a function that takes a Tensor batch of German data (as extracted from the training Dataset), and returns a tuple containing German inputs and outputs for the decoder model (refer to schematic diagram above).\n",
        "* Define a function that computes the forward and backward pass for your translation model. This function should take an English input, German input and German output as arguments, and should do the following:\n",
        "    * Pass the English input into the encoder, to get the hidden and cell states of the encoder LSTM.\n",
        "    * These hidden and cell states are then passed into the decoder, along with the German inputs, which returns a sequence of outputs (the hidden and cell state outputs of the decoder LSTM are unused in this function).\n",
        "    * The loss should then be computed between the decoder outputs and the German output function argument.\n",
        "    * The function returns the loss and gradients with respect to the encoder and decoder’s trainable variables.\n",
        "    * Decorate the function with @tf.function\n",
        "* Define and run a custom training loop for a number of epochs (for you to choose) that does the following:\n",
        "    * Iterates through the training dataset, and creates decoder inputs and outputs from the German sequences.\n",
        "    * Updates the parameters of the translation model using the gradients of the function above and an optimizer object.\n",
        "    * Every epoch, compute the validation loss on a number of batches from the validation and save the epoch training and validation losses.\n",
        "* Plot the learning curves for loss vs epoch for both training and validation sets.\n",
        "\n",
        "_Hint: This model is computationally demanding to train. The quality of the model or length of training is not a factor in the grading rubric. However, to obtain a better model we recommend using the GPU accelerator hardware on Colab._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "iYd4vBLsrXdb"
      },
      "outputs": [],
      "source": [
        "# Define a function that takes a Tensor batch of German data (as extracted from the training Dataset),\n",
        "# and returns a tuple containing German inputs and outputs for the decoder model (refer to schematic diagram above).\n",
        "\n",
        "def german_io(german):\n",
        "    input_data = german[:, 0:tf.shape(german)[1]-1]\n",
        "    output_data = german[:, 1:tf.shape(german)[1]]\n",
        "    return (input_data, output_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "hhGOfvQbrXdb"
      },
      "outputs": [],
      "source": [
        "# Define a function that computes the forward and backward pass for your translation model. This function should take an English input, German input and German output as arguments, and should do the following:\n",
        "## Pass the English input into the encoder, to get the hidden and cell states of the encoder LSTM.\n",
        "## These hidden and cell states are then passed into the decoder, along with the German inputs, which returns a sequence of outputs (the hidden and cell state outputs of the decoder LSTM are unused in this function).\n",
        "## The loss should then be computed between the decoder outputs and the German output function argument.\n",
        "## The function returns the loss and gradients with respect to the encoder and decoder’s trainable variables.\n",
        "## Decorate the function with @tf.function\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "@tf.function\n",
        "def fb_passes(english, german_input, german_output):\n",
        "    with tf.GradientTape() as tape:\n",
        "        hidden_state, cell_state = encoder_model(english)\n",
        "        dense_output, _, _ = decoder_model(german_input, hidden_state, cell_state)\n",
        "\n",
        "        loss = tf.math.reduce_mean(loss_object(german_output, dense_output))\n",
        "        trainable_variables = encoder_model.trainable_variables + decoder_model.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_variables)\n",
        "    return loss, gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "_68zPuWqrXdb"
      },
      "outputs": [],
      "source": [
        "# Define and run a custom training loop for a number of epochs (for you to choose) that does the following:\n",
        "# Iterates through the training dataset, and creates decoder inputs and outputs from the German sequences.\n",
        "# Updates the parameters of the translation model using the gradients of the function above and an optimizer object.\n",
        "# Every epoch, compute the validation loss on a number of batches from the validation and save the epoch training and validation losses.\n",
        "\n",
        "def train(epochs=9):\n",
        "\n",
        "    train_loss_results = []\n",
        "    val_loss_results = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        batch = 0\n",
        "\n",
        "        epoch_loss_avg_train = tf.keras.metrics.Mean()\n",
        "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "\n",
        "\n",
        "        # Training loop\n",
        "        for english_input, german_sequence in train_dataset:\n",
        "            german_input, german_output = german_io(german_sequence)\n",
        "            loss_train, gradients = fb_passes(english_input, german_input, german_output)\n",
        "            #epoch_loss += loss_train\n",
        "            #batch += 1\n",
        "\n",
        "\n",
        "\n",
        "            optimizer.apply_gradients(zip(gradients,\n",
        "                                          encoder_model.trainable_variables +\n",
        "                                          decoder_model.trainable_variables))\n",
        "            #epoch_avg_loss = epoch_loss / batch\n",
        "            #train_loss_results.append(loss_train)\n",
        "            epoch_loss_avg_train(loss_train)\n",
        "\n",
        "\n",
        "        epoch_loss = 0\n",
        "        batch = 0\n",
        "\n",
        "        # Validation loop\n",
        "        for english_input, german_sequence in val_dataset:\n",
        "            german_input, german_output = german_io(german_sequence)\n",
        "            loss, _ = fb_passes(english_input, german_input, german_output)\n",
        "            #epoch_loss += loss\n",
        "            #batch += 1\n",
        "\n",
        "            #epoch_avg_val_loss = epoch_loss / batch\n",
        "            #val_loss_results.append(loss)\n",
        "            epoch_loss_avg(loss)\n",
        "\n",
        "        print(\"Epoch {:02d}: Avg. training loss = {:.6f}, Avg. validation loss = {:.6f} \".format(epoch,\n",
        "                                                                                                 epoch_loss_avg_train.result(),\n",
        "                                                                                                 epoch_loss_avg.result()))\n",
        "        train_loss_results.append(epoch_loss_avg_train.result())\n",
        "        val_loss_results.append(epoch_loss_avg.result())\n",
        "\n",
        "    return train_loss_results, val_loss_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "FJdViWwGrXdb",
        "outputId": "4f6b59fa-eef9-496a-85da-2dfa32744a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 00: Avg. training loss = 3.333947, Avg. validation loss = 2.974573 \n",
            "Epoch 01: Avg. training loss = 2.701977, Avg. validation loss = 2.775671 \n",
            "Epoch 02: Avg. training loss = 2.449995, Avg. validation loss = 2.721727 \n",
            "Epoch 03: Avg. training loss = 2.266617, Avg. validation loss = 2.706872 \n",
            "Epoch 04: Avg. training loss = 2.090916, Avg. validation loss = 2.642876 \n",
            "Epoch 05: Avg. training loss = 1.903592, Avg. validation loss = 2.600928 \n",
            "Epoch 06: Avg. training loss = 1.728980, Avg. validation loss = 2.532535 \n",
            "Epoch 07: Avg. training loss = 1.573200, Avg. validation loss = 2.520372 \n",
            "Epoch 08: Avg. training loss = 1.448449, Avg. validation loss = 2.524906 \n"
          ]
        }
      ],
      "source": [
        "train_loss_results, val_loss_results = train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "KZ5RKLdWrXdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "outputId": "58437804-7afa-4b73-fb0c-6d3cca540a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from prettytable import PrettyTable\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print(len(train_loss_results))\n",
        "print(len(val_loss_results))\n",
        "\n",
        "fig = plt.figure(figsize = (10, 10))\n",
        "ax = fig.add_subplot(1,1,1)\n",
        "ax.plot(train_loss_results, label=\"Training\")\n",
        "ax.plot(val_loss_results, label=\"Validation\")\n",
        "ax.legend(loc='best')\n",
        "ax.set_title(\"Loss vs Epoch\")\n",
        "ax.set_xlabel(\"Epoch number\")\n",
        "ax.set_ylabel(\"Avg. loss\")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teSKnrcLrXdc"
      },
      "source": [
        "## 7. Use the model to translate\n",
        "Now it's time to put your model into practice! You should run your translation for five randomly sampled English sentences from the dataset. For each sentence, the process is as follows:\n",
        "* Preprocess and embed the English sentence according to the model requirements.\n",
        "* Pass the embedded sentence through the encoder to get the encoder hidden and cell states.\n",
        "* Starting with the special  `\"<start>\"` token, use this token and the final encoder hidden and cell states to get the one-step prediction from the decoder, as well as the decoder’s updated hidden and cell states.\n",
        "* Create a loop to get the next step prediction and updated hidden and cell states from the decoder, using the most recent hidden and cell states. Terminate the loop when the `\"<end>\"` token is emitted, or when the sentence has reached a maximum length.\n",
        "* Decode the output token sequence into German text and print the English text and the model's German translation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "MzWq7nL2rXdc"
      },
      "outputs": [],
      "source": [
        "random_ind = np.random.choice(5000, 5)\n",
        "examples = []\n",
        "for ind in random_ind:\n",
        "    examples.append(data_examples[ind])\n",
        "english_sentences = [sentence.split('\\t')[0] for sentence in examples]\n",
        "processed_english = []\n",
        "for sentence in english_sentences:\n",
        "    processed_english.append(preprocess_sentence(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "2o6zeVvCrXdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd90420-0bd0-42b9-bf5c-e5a523f2c628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I was tired.', 'er ist ein hammertyp .']\n",
            "[\"We're safe.\", 'bist du naechste .']\n",
            "[\"I'm freezing.\", 'er ist laestig .']\n",
            "[\"I'm upset.\", 'ich bin ruiniert .']\n",
            "['Write me.', 'er ist gestorben .']\n"
          ]
        }
      ],
      "source": [
        "start = tokenizer.word_index['<start>']\n",
        "end = tokenizer.word_index['<end>']\n",
        "examples_tokens = []\n",
        "for p_english in processed_english:\n",
        "    english = tf.strings.split(p_english,sep = \" \")\n",
        "    english = embedding_layer(english)\n",
        "    english = tf.pad(english, [[13-len(english), 0], [0, 0]], constant_values = 0)\n",
        "    english = tf.expand_dims(english, 0)\n",
        "    hidden_state, cell_state = encoder_model(english)\n",
        "    translated_tokens = []\n",
        "    tf_token = tf.Variable([[start]])\n",
        "    while True:\n",
        "        output_1,hidden_state, cell_state = decoder_model(tf_token, hidden_state, cell_state)\n",
        "        output_2 = tf.argmax(output_1, 2).numpy()[0,0]\n",
        "        tf_token = tf.Variable([[output_2]])\n",
        "        if output_2 == end:\n",
        "            break\n",
        "        else:\n",
        "            translated_tokens.append(output_2)\n",
        "    examples_tokens.append(translated_tokens)\n",
        "\n",
        "inv_german_index = {value:key for key,value in tokenizer.word_index.items()}\n",
        "german_sentences = []\n",
        "for example_token in examples_tokens:\n",
        "    output_words = []\n",
        "    for token in example_token:\n",
        "        output_words.append(inv_german_index[token])\n",
        "    output = \" \".join(output_words)\n",
        "    german_sentences.append(output)\n",
        "for english, german in zip(english_sentences,german_sentences):\n",
        "  print([english, german])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}